{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import fastai\n",
    "import torch \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "issue with keras and tensorflow library in machine-learning env\n",
    "use base python(3.11.5) for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading images\n",
    "img=cv.imread(\"C:\\\\Users\\\\soume\\\\Desktop\\\\photo0637.jpg\") # use double quotes for path\n",
    "cv.imshow('2013',img)\n",
    "cv.waitKey(0) #wait for that time for which it displays the image\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading videos\n",
    "capture=cv.VideoCapture(1) #0 for webcam,1  for first ex cam,  2... ,or mention file path under single quotues for a specific video\n",
    "while True:\n",
    "    isTrue,frame=capture.read()\n",
    "    cv.imshow('Stream',frame)\n",
    "\n",
    "    if cv.waitKey(20) & 0xFF==ord('d'):  # breaks out from loop either by pressing d\n",
    "        break\n",
    "capture.release()\n",
    "cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rescaling videos  and resizing images\n",
    "def rescaleFrame(frame,scale=0.25):     # by 75% down scaled\n",
    "    width=int(frame.shape[1]*scale)     # shape[1] is width  and then typecasted\n",
    "    height=int(frame.shape[0]*scale)    # shape[0] is height and then typecasted\n",
    "    dimensions=(width,height)\n",
    "\n",
    "    return cv.resize(frame,dimensions,interpolation=cv.INTER_AREA)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescaling videos  and resizing images\n",
    "'''def rescaleFrame(frame,scale=0.75):     # by 50% down scaled\n",
    "    width=int(frame.shape[1]*scale)     # shape[1] is width  and then typecasted\n",
    "    height=int(frame.shape[0]*scale)    # shape[0] is height and then typecasted\n",
    "    dimensions=(width,height)\n",
    "\n",
    "    return cv.resize(frame,dimensions,interpolation=cv.INTER_AREA)'''\n",
    "\n",
    "cv.waitKey(0)\n",
    "#reading videos\n",
    "capture=cv.VideoCapture(1) #0 for webcam,1  for first ex cam,  2... ,or mention file path under single quotues for a specific video\n",
    "while True:\n",
    "    isTrue,frame=capture.read()\n",
    "    frame_resized=rescaleFrame(frame)\n",
    "    #cv.imshow('WebCam',frame)\n",
    "    cv.imshow('Webcam_ReSized',frame_resized)\n",
    "\n",
    "\n",
    "    if cv.waitKey(20) & 0xFF==ord('d'):  # breaks out from loop either by pressing d\n",
    "        break\n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific for live video \n",
    "def changeRes(width,height):\n",
    "    capture.set(3,width)         #3 refers a property\n",
    "    capture.set(4,height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#thresholding--binarization of a image(black nd white --- 0 1 scenario)\n",
    "import cv2 as cv\n",
    "img=cv.imread(\"C:\\\\Users\\\\soume\\\\Desktop\\\\photo0637.jpg\")\n",
    "#cv.imshow('2013',img)\n",
    "rescaled=rescaleFrame(img)\n",
    "gray=cv.cvtColor(rescaled,cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gr',rescaled)\n",
    "\n",
    "#Simple Thresholding\n",
    "threshold, thresh=cv.threshold(gray,150,255,cv.THRESH_BINARY) # compares each pixel value and set it to 255 or 0 depending upon whether its above the threshold or below\n",
    "threshold, thresh_inv=cv.threshold(gray,150,255,cv.THRESH_BINARY_INV) # compares each pixel value and set it to 255 or 0 depending upon whether its above the threshold or below\n",
    "cv.imshow('Simple Threshold Inverse',thresh_inv)\n",
    "cv.waitKey(0)\n",
    "\n",
    "#Adaptive Threshold\n",
    "adaptive_thresh=cv.adaptiveThreshold(gray,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,cv.THRESH_BINARY,9,1)\n",
    "cv.imshow('Adaptive Thresholding',adaptive_thresh)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5 essential functions in opencv\n",
    "def rescaleFrame(frame,scale=0.25):     # by 75% down scaled\n",
    "    width=int(frame.shape[1]*scale)     # shape[1] is width  and then typecasted\n",
    "    height=int(frame.shape[0]*scale)    # shape[0] is height and then typecasted\n",
    "    dimensions=(width,height)\n",
    "\n",
    "    return cv.resize(frame,dimensions,interpolation=cv.INTER_AREA)\n",
    "#converting a image to greyscale\n",
    "img=cv.imread('C:\\\\Users\\\\soume\\\\Desktop\\\\jk.jpg')\n",
    "frame_resized=rescaleFrame(img)\n",
    "'''cv.imshow('pho',frame_resized)\n",
    "gray=cv.cvtColor(frame_resized,cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('GS',gray)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()'''\n",
    "\n",
    "#blurring an image(gaussian blur)\n",
    "blur=cv.GaussianBlur(frame_resized,(3,3),cv.BORDER_DEFAULT)  # src,kernel size,attribute ,,,increasing kernel size increase blur intensity\n",
    "cv.imshow('BLUR',blur)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "#Edge Cascade (canny edge detector)\n",
    "canny=cv.Canny(frame_resized,125,175)  #we have 3 parameters to consider: (1) the size of the Gaussian filter, (2) the low and (3) high threshold for the hysteresis thresholding. \n",
    "cv.imshow('Canny Egdes',canny)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "#Dilating the image\n",
    "dilated=cv.dilate(canny,(7,7),iterations=3)\n",
    "cv.imshow('dil',dilated)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "# Eroding\n",
    "eroded=cv.erode(dilated,(7,7),iterations=3)\n",
    "cv.imshow('Eroded',eroded)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "#Resize\n",
    "resized=cv.resize(img,(500,500),interpolation=cv.INTER_AREA)  #inter area--scaling down,,,inter linear/cubic for scaling up ,,,,highest quality-->cubic\n",
    "cv.imshow('resized',resized)\n",
    "cv.waitKey(0)\n",
    "\n",
    "#Cropping\n",
    "cropped=img[50:200,200:400]\n",
    "cv.imshow('Cropped',cropped)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contour Detection\n",
    "def rescaleFrame(frame,scale=0.15):     # by 85% down scaled\n",
    "    width=int(frame.shape[1]*scale)     # shape[1] is width  and then typecasted\n",
    "    height=int(frame.shape[0]*scale)    # shape[0] is height and then typecasted\n",
    "    dimensions=(width,height)\n",
    "\n",
    "    return cv.resize(frame,dimensions,interpolation=cv.INTER_AREA)\n",
    "\n",
    "#converting a image to greyscale\n",
    "img=cv.imread('C:\\\\Users\\\\soume\\\\Desktop\\\\jk.jpg')\n",
    "frame_resized=rescaleFrame(img)\n",
    "cv.imshow('pho',frame_resized)\n",
    "\n",
    "gray=cv.cvtColor(frame_resized,cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('GS',gray)\n",
    "\n",
    "blur=cv.GaussianBlur(frame_resized,(3,3),cv.BORDER_DEFAULT)\n",
    "\n",
    "canny=cv.Canny(blur,125,175)\n",
    "cv.imshow('Canny Edges',canny)\n",
    "\n",
    "'''ret,thresh=cv.threshold(gray,155,255,cv.THRESH_BINARY)\n",
    "cv.imshow('THresholded',thresh)'''\n",
    "\n",
    "contours,hierarchies=cv.findContours(canny,cv.RETR_LIST,cv.CHAIN_APPROX_SIMPLE)   #returns two things  contours list,hierarchics list anda takes,src,mode of det,approx tech.\n",
    "print(f'{len(contours)} contour(s) found!')\n",
    "print(hierarchies)\n",
    "print(\"-----------------------------------\")\n",
    "print(contours)\n",
    "\n",
    "\n",
    "#drawing contours of a image on a blank space babbyyy!!\n",
    "blank=np.zeros(img.shape,dtype='uint8')\n",
    "frame_resized1=rescaleFrame(blank)\n",
    "cv.imshow('Blank',frame_resized1)\n",
    "cv.drawContours(frame_resized1,contours,-1,(0,0,255),1)  # sink,source,contours_idx(-1 for all),color(bgr),thickness of line\n",
    "cv.imshow(\"Contoursss\",frame_resized1)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edges are computed as points that are extrema of the image gradient in the direction of the gradient. In other words, they are points with values significantly different from the values of the neighbor points.\n",
    "\n",
    "While, on the other hand, Contours are close curves that are obtained from edges representing the boundary of a figure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m canny\u001b[38;5;241m=\u001b[39mcv\u001b[38;5;241m.\u001b[39mCanny(re_img1,\u001b[38;5;241m175\u001b[39m,\u001b[38;5;241m255\u001b[39m)\n\u001b[0;32m     31\u001b[0m cv\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCanny\u001b[39m\u001b[38;5;124m'\u001b[39m,canny)\n\u001b[1;32m---> 32\u001b[0m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m cv\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Edge Detection\n",
    "\n",
    "def rescaleFrame(frame,scale=0.30):     # by 70% down scaled\n",
    "    width=int(frame.shape[1]*scale)     # shape[1] is width  and then typecasted\n",
    "    height=int(frame.shape[0]*scale)    # shape[0] is height and then typecasted\n",
    "    dimensions=(width,height)\n",
    "\n",
    "    return cv.resize(frame,dimensions,interpolation=cv.INTER_AREA)\n",
    "\n",
    "img1=cv.imread(\"C:\\\\Users\\\\soume\\Desktop\\\\Image1786.jpg\")\n",
    "re_img1=rescaleFrame(img1)\n",
    "cv.imshow(\"ME_:)\",re_img1)\n",
    "\n",
    "gray=cv.cvtColor(re_img1,cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('re',gray)\n",
    "\n",
    "lap=cv.Laplacian(gray,cv.CV_64F)     #Laplacian techniquee\n",
    "lap=np.uint8(np.absolute(lap))\n",
    "cv.imshow(\"LAPPP\",lap)\n",
    "\n",
    "#Sobel gradient mag rep\n",
    "sobelx=cv.Sobel(gray,cv.CV_64F,1,0)  #src,d_depth,x_Dir,y_dir\n",
    "sobely=cv.Sobel(gray,cv.CV_64F,0,1)\n",
    "combined_sobel=cv.bitwise_or(sobelx,sobely)\n",
    "cv.imshow('Sobel X',sobelx)\n",
    "cv.imshow('Sobel Y',sobely)\n",
    "cv.imshow('combo',combined_sobel)\n",
    "\n",
    "#canny\n",
    "canny=cv.Canny(re_img1,175,255)\n",
    "cv.imshow('Canny',canny)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Face Recognition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
